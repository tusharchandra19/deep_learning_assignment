{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math as math\n",
    "def normpdf(x, mean, sd):\n",
    "    var = float(sd)**2\n",
    "    denom = (2*math.pi*var)**.5\n",
    "    num = math.exp(-(float(x)-float(mean))**2/(2*var))\n",
    "    return num/denom\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "train=[]\n",
    "w = [0.4,0.3,0.3]\n",
    "out = []\n",
    "for i in range(10000):\n",
    "    x_out=[]\n",
    "    x = random.random()\n",
    "    x1 = normpdf(x,0,4)\n",
    "    x2 = normpdf(x,-6,4)\n",
    "    x3 = normpdf(x,6,4)\n",
    "    x_out.append(x1)\n",
    "    x_out.append(x2)\n",
    "    x_out.append(x3)\n",
    "    x_out = np.asarray(x_out)\n",
    "    out.append(0.4*x1 + 0.3*x2 + 0.3*x3)\n",
    "    train.append(x_out)\n",
    "    \n",
    "train = np.asarray(train,np.float64)\n",
    "out = np.asarray(out,np.float64)\n",
    "out = torch.from_numpy(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, hidden_dim, output_size):\n",
    "        super(Discriminator, self).__init__()\n",
    "        \n",
    "        # define hidden linear layers\n",
    "        self.fc1 = nn.Linear(input_size, hidden_dim*2)\n",
    "        self.fc2 = nn.Linear(hidden_dim*2, hidden_dim)\n",
    "        \n",
    "        # final fully-connected layer\n",
    "        self.fc3 = nn.Linear(hidden_dim, output_size)\n",
    "        \n",
    "        # dropout layer \n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        # all hidden layers\n",
    "        x = F.leaky_relu(self.fc1(x), 0.2) # (input, negative_slope=0.2)\n",
    "        x = self.dropout(x)\n",
    "        x = F.leaky_relu(self.fc2(x), 0.2)\n",
    "        x = self.dropout(x)\n",
    "        # final layer\n",
    "        out = self.fc3(x)\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, hidden_dim, output_size):\n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "        # define hidden linear layers\n",
    "        self.fc1 = nn.Linear(input_size, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, hidden_dim*2)\n",
    "        \n",
    "        # final fully-connected layer\n",
    "        self.fc3 = nn.Linear(hidden_dim*2, output_size)\n",
    "        \n",
    "        # dropout layer \n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # all hidden layers\n",
    "        x = F.leaky_relu(self.fc1(x), 0.2) # (input, negative_slope=0.2)\n",
    "        x = self.dropout(x)\n",
    "        x = F.leaky_relu(self.fc2(x), 0.2)\n",
    "        x = self.dropout(x)\n",
    "        # final layer with tanh applied\n",
    "        out = F.tanh(self.fc3(x))\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discriminator hyperparams\n",
    "\n",
    "# Size of input image to discriminator \n",
    "input_size = 3\n",
    "# Size of discriminator output (real or fake)\n",
    "d_output_size = 1\n",
    "# Size of last hidden layer in the discriminator\n",
    "d_hidden_size = 8\n",
    "\n",
    "# Generator hyperparams\n",
    "\n",
    "# Size of latent vector to give to generator\n",
    "z_size = 10\n",
    "# Size of discriminator output (generated image)\n",
    "g_output_size = 3\n",
    "# Size of first hidden layer in the generator\n",
    "g_hidden_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator(\n",
      "  (fc1): Linear(in_features=3, out_features=16, bias=True)\n",
      "  (fc2): Linear(in_features=16, out_features=8, bias=True)\n",
      "  (fc3): Linear(in_features=8, out_features=1, bias=True)\n",
      "  (dropout): Dropout(p=0.3, inplace=False)\n",
      ")\n",
      "\n",
      "Generator(\n",
      "  (fc1): Linear(in_features=10, out_features=8, bias=True)\n",
      "  (fc2): Linear(in_features=8, out_features=16, bias=True)\n",
      "  (fc3): Linear(in_features=16, out_features=3, bias=True)\n",
      "  (dropout): Dropout(p=0.3, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# instantiate discriminator and generator\n",
    "D = Discriminator(input_size, d_hidden_size, d_output_size)\n",
    "G = Generator(z_size, g_hidden_size, g_output_size)\n",
    "\n",
    "# check that they are as you expect\n",
    "print(D)\n",
    "print()\n",
    "print(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# Optimizers\n",
    "lr = 0.002\n",
    "\n",
    "# Create optimizers for the discriminator and generator\n",
    "d_optimizer = optim.Adam(D.parameters(), lr)\n",
    "g_optimizer = optim.Adam(G.parameters(), lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\tushar\\anaconda3\\envs\\conda_pip_env\\lib\\site-packages\\torch\\nn\\functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [    1/   20] | d_loss: 1.5119 | g_loss: 0.7462\n",
      "Epoch [    2/   20] | d_loss: 0.4489 | g_loss: 0.2244\n",
      "Epoch [    3/   20] | d_loss: 0.4489 | g_loss: 0.2244\n",
      "Epoch [    4/   20] | d_loss: 0.4489 | g_loss: 0.2244\n",
      "Epoch [    5/   20] | d_loss: 0.4489 | g_loss: 0.2244\n",
      "Epoch [    6/   20] | d_loss: 0.4489 | g_loss: 0.2244\n",
      "Epoch [    7/   20] | d_loss: 0.4489 | g_loss: 0.2244\n",
      "Epoch [    8/   20] | d_loss: 0.4489 | g_loss: 0.2244\n",
      "Epoch [    9/   20] | d_loss: 0.4489 | g_loss: 0.2244\n",
      "Epoch [   10/   20] | d_loss: 0.4489 | g_loss: 0.2244\n",
      "Epoch [   11/   20] | d_loss: 0.4489 | g_loss: 0.2244\n",
      "Epoch [   12/   20] | d_loss: 0.4489 | g_loss: 0.2244\n",
      "Epoch [   13/   20] | d_loss: 0.4489 | g_loss: 0.2244\n",
      "Epoch [   14/   20] | d_loss: 0.4489 | g_loss: 0.2244\n",
      "Epoch [   15/   20] | d_loss: 0.4489 | g_loss: 0.2244\n",
      "Epoch [   16/   20] | d_loss: 0.4489 | g_loss: 0.2244\n",
      "Epoch [   17/   20] | d_loss: 0.4489 | g_loss: 0.2244\n",
      "Epoch [   18/   20] | d_loss: 0.4489 | g_loss: 0.2244\n",
      "Epoch [   19/   20] | d_loss: 0.4489 | g_loss: 0.2244\n",
      "Epoch [   20/   20] | d_loss: 0.4489 | g_loss: 0.2244\n"
     ]
    }
   ],
   "source": [
    "import pickle as pkl\n",
    "\n",
    "# training hyperparams\n",
    "num_epochs = 20\n",
    "batch_size=256\n",
    "# keep track of loss and generated, \"fake\" samples\n",
    "samples = []\n",
    "lossesd = []\n",
    "lossesg=[]\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "# Get some fixed data for sampling. These are images that are held\n",
    "# constant throughout training, and allow us to inspect the model's performance\n",
    "sample_size=16\n",
    "fixed_z = np.random.uniform(-1, 1, size=(sample_size, z_size))\n",
    "fixed_z = torch.from_numpy(fixed_z).float()\n",
    "\n",
    "# train the network\n",
    "D.train()\n",
    "G.train()\n",
    "epochs=[]\n",
    "for epoch in range(num_epochs):\n",
    "    j=0\n",
    "    for t in train:\n",
    "                \n",
    "                \n",
    "        # ============================================\n",
    "        #            TRAIN THE DISCRIMINATOR\n",
    "        # ============================================\n",
    "        \n",
    "        d_optimizer.zero_grad()\n",
    "        \n",
    "        # 1. Train with real images\n",
    "\n",
    "        # Compute the discriminator losses on real images \n",
    "        # smooth the real labels\n",
    "        t = torch.from_numpy(t).float()\n",
    "        D_real = D(t)\n",
    "        output = torch.tensor([out[j]])\n",
    "\n",
    "        d_real_loss = criterion(D_real, output)\n",
    "        \n",
    "        # 2. Train with fake images\n",
    "        \n",
    "        # Generate fake examples\n",
    "        z = np.random.uniform(-1, 1, size=10)\n",
    "        z = torch.from_numpy(z).float()\n",
    "        fake_t = G(z)\n",
    "        \n",
    "        # Compute the discriminator losses on fake data       \n",
    "        D_fake = D(fake_t)\n",
    "        output = torch.tensor([out[j]])\n",
    "        \n",
    "        d_fake_loss = criterion(D_fake,output)\n",
    "        \n",
    "        # add up loss and perform backprop\n",
    "        d_loss = d_real_loss + d_fake_loss\n",
    "        d_loss.backward()\n",
    "        d_optimizer.step()\n",
    "        \n",
    "        \n",
    "        # =========================================\n",
    "        #            TRAIN THE GENERATOR\n",
    "        # =========================================\n",
    "        g_optimizer.zero_grad()\n",
    "        \n",
    "        # 1. Train with fake images and flipped labels\n",
    "        \n",
    "        # Generate fake images\n",
    "        z = np.random.uniform(-1, 1, size=10)\n",
    "        z = torch.from_numpy(z).float()\n",
    "        fake_t = G(z)\n",
    "        \n",
    "        # Compute the discriminator losses on fake images \n",
    "        # using flipped labels!\n",
    "        D_fake = D(fake_t)\n",
    "        output = torch.tensor([out[j]])\n",
    "\n",
    "        g_loss = criterion(D_fake,output) # use real loss to flip labels\n",
    "        \n",
    "        # perform backprop\n",
    "        g_loss.backward()\n",
    "        g_optimizer.step()\n",
    "        \n",
    "        if j == 0:\n",
    "            # print discriminator and generator loss\n",
    "            print('Epoch [{:5d}/{:5d}] | d_loss: {:6.4f} | g_loss: {:6.4f}'.format(\n",
    "                    epoch+1, num_epochs, d_loss.item(), g_loss.item()))\n",
    "            \n",
    "            \n",
    "        j+=1\n",
    "\n",
    "    epochs.append(epoch)\n",
    "    ## AFTER EACH EPOCH##\n",
    "    # append discriminator loss and generator loss\n",
    "    lossesd.append(d_loss.item())\n",
    "    lossesg.append(g_loss.item())\n",
    "    \n",
    "    # generate and save sample, fake images\n",
    "    G.eval() # eval mode for generating samples\n",
    "    samples_z = G(fixed_z)\n",
    "    samples.append(samples_z)\n",
    "    G.train() # back to train mode\n",
    "\n",
    "    \n",
    "# Save training generator samples\n",
    "with open('train_samples.pkl', 'wb') as f:\n",
    "    pkl.dump(samples, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1e16d010f08>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(epochs,lossesd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "list_sam = []\n",
    "for i in range(20):\n",
    "    for j in range(16):\n",
    "        listing=[]\n",
    "        for k in range(3):\n",
    "            item = samples[i][j][k].detach().numpy()\n",
    "            listing.append(item)\n",
    "            \n",
    "        list_sam.append(listing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(list_sam, bins=3, density=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianMixture(covariance_type='full', init_params='random', max_iter=100,\n",
       "        means_init=None, n_components=3, n_init=1, precisions_init=None,\n",
       "        random_state=None, reg_covar=1e-06, tol=0.001, verbose=0,\n",
       "        verbose_interval=10, warm_start=False, weights_init=None)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "model = GaussianMixture(n_components=3, init_params='random')\n",
    "model.fit(list_sam)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 2 1 1 1 2 2 2 1 2 1 2 1 2 1 2 1 0 0 0 0]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "yhat1 = model.predict(list_sam)\n",
    "\n",
    "# check latent value for first few points\n",
    "print(yhat1[:100])\n",
    "# check latent value for last few points\n",
    "print(yhat1[-100:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianMixture(covariance_type='full', init_params='random', max_iter=100,\n",
       "        means_init=None, n_components=3, n_init=1, precisions_init=None,\n",
       "        random_state=None, reg_covar=1e-06, tol=0.001, verbose=0,\n",
       "        verbose_interval=10, warm_start=False, weights_init=None)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GaussianMixture(n_components=3, init_params='random')\n",
    "model.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 2 0 0 0 2 2 2 2 0 2 2 0 0 2 0 2 2 2 0 0 0 2 2 0 0 0 2 0 2 0 0 0\n",
      " 0 0 0 0 0 0 2 2 2 2 0 2 2 0 2 2 0 0 2 0 0 0 0 0 0 2 2 2 2 2 2 0 0 2 2 0 0\n",
      " 0 0 2 0 2 2 0 2 2 0 2 2 0 0 0 0 0 2 2 2 0 0 0 0 2 2]\n",
      "[2 0 0 2 2 2 0 0 0 0 2 0 0 2 0 2 2 2 0 0 0 2 0 2 0 0 2 0 0 0 2 0 0 0 0 0 2\n",
      " 2 0 0 0 2 2 2 2 0 0 0 2 2 0 0 0 0 0 2 2 0 2 2 2 0 0 2 2 0 0 2 2 0 0 2 2 2\n",
      " 2 2 2 0 2 2 2 2 0 2 2 2 2 0 2 0 0 0 2 0 2 2 2 0 2 2]\n"
     ]
    }
   ],
   "source": [
    "yhat2 = model.predict(train)\n",
    "\n",
    "# check latent value for first few points\n",
    "print(yhat2[:100])\n",
    "# check latent value for last few points\n",
    "print(yhat2[-100:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def kl_divergence(p, q):\n",
    "    a=0\n",
    "    for i in range(len(p)):\n",
    "        if(q[i]!=0):\n",
    "            if((p[i]/q[i])>0):\n",
    "                a+=sum(p[i] * math.log2(p[i]/q[i]))          \n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KL(P || Q): 0.000 bits\n"
     ]
    }
   ],
   "source": [
    "loss=0\n",
    "yhat1 = torch.from_numpy(yhat1)\n",
    "yhat2 = torch.from_numpy(yhat2)\n",
    "\n",
    "sum1 = sum(yhat1)\n",
    "for i in range(len(yhat1)):\n",
    "    yhat1[i] = yhat1[i]/sum1\n",
    "sum2 = sum(yhat2)\n",
    "for i in range(len(yhat2)):\n",
    "    yhat2[i] = yhat2[i]/sum1    \n",
    "\n",
    "\n",
    "kl_pq = kl_divergence(yhat1, yhat2)\n",
    "print('KL(P || Q): %.3f bits' % kl_pq)\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
